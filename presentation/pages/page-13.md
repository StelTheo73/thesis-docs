# Evaluation

<p class='slide-subtitle'>Methodology</p>

<div class='section-wrapper'>
  <h2>The evaluation process used a mix of methods:</h2>
  <ul class='flex-list'>
        <li>Pre-Post Tests [L]: Evaluation of learning outcome (23 participants)</li>
        <li>System Usability Scale Questionnaire [L]: Evaluation of the game as an interactive system (15 participants)</li>
        <li>Game User Experience Satisfaction Scale [L]: Evaluation of the game experience (15 participants)</li>
        <li>Focus Group [L]: Qualitative feedback & Confirmation of questionnaire results (8 participants)</li>
        <li>Post Test Repetition: Evaluation of knowledge retention (10 participants)</li>
  </ul>
  <hr v-click='+1' class="divider grey-shadow"/>
  <p v-click='+1'>
    To measure the effectiveness of the game as a learning tool, we used the <em>Average Normalized Gain</em> metric [L]:
  </p>
  <div v-click='+1' class='img-wrapper grey-shadow bg-white-smoke rounded-md'>
    <img src='../assets/average_gain.png' class='rounded-md'/>
  </div>
</div>

<style>
  h2 {
    margin-bottom: 0.5em;
  }

  .img-wrapper {
    width: max-content;
    position: absolute;
    left: 30%;
    padding: 0.5em;
  }
</style>